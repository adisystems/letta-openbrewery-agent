agent_type='memgpt_agent' core_memory=[] created_at='2025-04-10T18:28:08.237356+00:00' description='An assistant that provides brewery info across U.S. states' embedding_config=EmbeddingConfig(embedding_endpoint_type='hugging-face', embedding_endpoint='https://embeddings.memgpt.ai', embedding_model='letta-free', embedding_dim=1024, embedding_chunk_size=300, handle='letta/letta-free', azure_endpoint=None, azure_version=None, azure_deployment=None) llm_config=LlmConfig(model='letta-free', model_endpoint_type='openai', model_endpoint='https://inference.memgpt.ai', model_wrapper=None, context_window=8192, put_inner_thoughts_in_kwargs=True, handle='letta/letta-free', temperature=0.7, max_tokens=4096, enable_reasoner=False, max_reasoning_tokens=0) message_buffer_autoclear=False in_context_message_indices=[0, 1, 2, 3] messages=[MessageSchema(created_at='2025-04-10T18:28:08.260132+00:00', group_id=None, model='letta-free', name=None, role='system', content=[TextContent(type='text', text='You are a helpful assistant that provides information about U.S. breweries.\n\nYou can:\n- Provide a complete list of all breweries in California using the california_breweries tool\n- Answer questions about breweries in other U.S. states using the ask_state_brewery_mcp tool\n- Answer questions about total count, types, or top cities for breweries\n\nWhen responding:\n1. Be clear and organized\n2. ALWAYS use the appropriate tool when a user asks about breweries in a specific state\n3. For questions about California, use the california_breweries tool\n4. For questions about ANY OTHER state, use the ask_state_brewery_mcp tool\n5. Summarize the information in a user-friendly way\n\nExample: If asked "How many breweries are in Texas?", use the ask_state_brewery_mcp tool and pass the entire question as the query parameter.\nWhen you get information from a tool, always use the send_message tool to show the information to the user.\n\n### Memory [last modified: 2025-04-10 02:28:08 PM EDT-0400]\n0 previous messages between you and the user are stored in recall memory (use functions to access them)\n0 total memories you created are stored in archival memory (use functions to access them)\n\n\nCore memory shown below (limited in size, additional information stored in archival / recall memory):\n')], tool_call_id=None, tool_calls=[], tool_returns=[], updated_at='2025-04-10T18:28:08.263213+00:00'), MessageSchema(created_at='2025-04-10T18:28:08.261884+00:00', group_id=None, model='letta-free', name=None, role='assistant', content=[TextContent(type='text', text='Bootup sequence complete. Persona activated. Testing messaging functionality.')], tool_call_id=None, tool_calls=[{'id': '4aad4afc-d5ec-4502-82bf-25ad3e20ac09', 'function': {'arguments': '{\n  "message": "More human than human is our motto."\n}', 'name': 'send_message'}, 'type': 'function'}], tool_returns=[], updated_at='2025-04-10T18:28:08.263213+00:00'), MessageSchema(created_at='2025-04-10T18:28:08.261909+00:00', group_id=None, model='letta-free', name=None, role='tool', content=[TextContent(type='text', text='{\n  "status": "OK",\n  "message": null,\n  "time": "2025-04-10 02:28:08 PM EDT-0400"\n}')], tool_call_id='4aad4afc-d5ec-4502-82bf-25ad3e20ac09', tool_calls=[], tool_returns=[], updated_at='2025-04-10T18:28:08.263213+00:00'), MessageSchema(created_at='2025-04-10T18:28:08.261920+00:00', group_id=None, model='letta-free', name=None, role='user', content=[TextContent(type='text', text='{\n  "type": "login",\n  "last_login": "Never (first login)",\n  "time": "2025-04-10 02:28:08 PM EDT-0400"\n}')], tool_call_id=None, tool_calls=[], tool_returns=[], updated_at='2025-04-10T18:28:08.263213+00:00')] metadata=None multi_agent_group=None name='brewery_assistant_336ca3de' system='You are a helpful assistant that provides information about U.S. breweries.\n\nYou can:\n- Provide a complete list of all breweries in California using the california_breweries tool\n- Answer questions about breweries in other U.S. states using the ask_state_brewery_mcp tool\n- Answer questions about total count, types, or top cities for breweries\n\nWhen responding:\n1. Be clear and organized\n2. ALWAYS use the appropriate tool when a user asks about breweries in a specific state\n3. For questions about California, use the california_breweries tool\n4. For questions about ANY OTHER state, use the ask_state_brewery_mcp tool\n5. Summarize the information in a user-friendly way\n\nExample: If asked "How many breweries are in Texas?", use the ask_state_brewery_mcp tool and pass the entire question as the query parameter.\nWhen you get information from a tool, always use the send_message tool to show the information to the user.\n' tags=[] tool_exec_environment_variables=[] tool_rules=[BaseToolRuleSchema(tool_name='send_message', type='exit_loop'), BaseToolRuleSchema(tool_name='conversation_search', type='continue_loop'), BaseToolRuleSchema(tool_name='archival_memory_insert', type='continue_loop'), BaseToolRuleSchema(tool_name='archival_memory_search', type='continue_loop')] tools=[ToolSchema(args_json_schema=None, created_at='2025-04-10T17:42:41.296718+00:00', description='Search archival memory using semantic (embedding-based) search.', json_schema=ToolJsonSchema(name='archival_memory_search', description='Search archival memory using semantic (embedding-based) search.', parameters=ParametersSchema(type='object', properties={'query': ParameterProperties(type='string', description='String to search for.'), 'page': ParameterProperties(type='integer', description='Allows you to page through results. Only use on a follow-up query. Defaults to 0 (first page).'), 'start': ParameterProperties(type='integer', description='Starting index for the search results. Defaults to 0.'), 'request_heartbeat': ParameterProperties(type='boolean', description='Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.')}, required=['query', 'request_heartbeat']), type=None, required=[]), name='archival_memory_search', return_char_limit=1000000, source_code=None, source_type='python', tags=['letta_core'], tool_type='letta_core', updated_at='2025-04-10T18:20:56.946862+00:00', metadata={}), ToolSchema(args_json_schema=None, created_at='2025-04-10T17:42:41.298898+00:00', description='Search prior conversation history using case-insensitive string matching.', json_schema=ToolJsonSchema(name='conversation_search', description='Search prior conversation history using case-insensitive string matching.', parameters=ParametersSchema(type='object', properties={'query': ParameterProperties(type='string', description='String to search for.'), 'page': ParameterProperties(type='integer', description='Allows you to page through results. Only use on a follow-up query. Defaults to 0 (first page).'), 'request_heartbeat': ParameterProperties(type='boolean', description='Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.')}, required=['query', 'request_heartbeat']), type=None, required=[]), name='conversation_search', return_char_limit=1000000, source_code=None, source_type='python', tags=['letta_core'], tool_type='letta_core', updated_at='2025-04-10T18:20:56.950043+00:00', metadata={}), ToolSchema(args_json_schema=None, created_at='2025-04-10T17:42:41.300823+00:00', description='Append to the contents of core memory.', json_schema=ToolJsonSchema(name='core_memory_append', description='Append to the contents of core memory.', parameters=ParametersSchema(type='object', properties={'label': ParameterProperties(type='string', description='Section of the memory to be edited (persona or human).'), 'content': ParameterProperties(type='string', description='Content to write to the memory. All unicode (including emojis) are supported.'), 'request_heartbeat': ParameterProperties(type='boolean', description='Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.')}, required=['label', 'content', 'request_heartbeat']), type=None, required=[]), name='core_memory_append', return_char_limit=1000000, source_code=None, source_type='python', tags=['letta_memory_core'], tool_type='letta_memory_core', updated_at='2025-04-10T18:20:56.952954+00:00', metadata={}), ToolSchema(args_json_schema=None, created_at='2025-04-10T17:42:41.303005+00:00', description='Replace the contents of core memory. To delete memories, use an empty string for new_content.', json_schema=ToolJsonSchema(name='core_memory_replace', description='Replace the contents of core memory. To delete memories, use an empty string for new_content.', parameters=ParametersSchema(type='object', properties={'label': ParameterProperties(type='string', description='Section of the memory to be edited (persona or human).'), 'old_content': ParameterProperties(type='string', description='String to replace. Must be an exact match.'), 'new_content': ParameterProperties(type='string', description='Content to write to the memory. All unicode (including emojis) are supported.'), 'request_heartbeat': ParameterProperties(type='boolean', description='Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.')}, required=['label', 'old_content', 'new_content', 'request_heartbeat']), type=None, required=[]), name='core_memory_replace', return_char_limit=1000000, source_code=None, source_type='python', tags=['letta_memory_core'], tool_type='letta_memory_core', updated_at='2025-04-10T18:20:56.955833+00:00', metadata={}), ToolSchema(args_json_schema=None, created_at='2025-04-10T17:42:41.305008+00:00', description='Sends a message to the human user.', json_schema=ToolJsonSchema(name='send_message', description='Sends a message to the human user.', parameters=ParametersSchema(type='object', properties={'message': ParameterProperties(type='string', description='Message contents. All unicode (including emojis) are supported.'), 'request_heartbeat': ParameterProperties(type='boolean', description='Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.')}, required=['message', 'request_heartbeat']), type=None, required=[]), name='send_message', return_char_limit=1000000, source_code=None, source_type='python', tags=['letta_core'], tool_type='letta_core', updated_at='2025-04-10T18:20:56.958606+00:00', metadata={}), ToolSchema(args_json_schema=None, created_at='2025-04-10T17:42:41.293905+00:00', description='Add to archival memory. Make sure to phrase the memory contents such that it can be easily queried later.', json_schema=ToolJsonSchema(name='archival_memory_insert', description='Add to archival memory. Make sure to phrase the memory contents such that it can be easily queried later.', parameters=ParametersSchema(type='object', properties={'content': ParameterProperties(type='string', description='Content to write to the memory. All unicode (including emojis) are supported.'), 'request_heartbeat': ParameterProperties(type='boolean', description='Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.')}, required=['content', 'request_heartbeat']), type=None, required=[]), name='archival_memory_insert', return_char_limit=1000000, source_code=None, source_type='python', tags=['letta_core'], tool_type='letta_core', updated_at='2025-04-10T18:20:56.942107+00:00', metadata={}), ToolSchema(args_json_schema=None, created_at='2025-04-10T18:28:08.212617+00:00', description='Answer state-level brewery questions using MCP', json_schema=ToolJsonSchema(name='ask_state_brewery_mcp', description='Queries the MCP server to retrieve brewery-related information for a specific state.', parameters=ParametersSchema(type='object', properties={'query': ParameterProperties(type='string', description='The user\'s natural language query (e.g., "How many breweries are in Texas?")'), 'request_heartbeat': ParameterProperties(type='boolean', description='Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.')}, required=['query', 'request_heartbeat']), type=None, required=[]), name='ask_state_brewery_mcp', return_char_limit=6000, source_code='\nimport requests\n\ndef ask_state_brewery_mcp(query: str) -> str:\n    """\n    Queries the MCP server to retrieve brewery-related information for a specific state.\n\n    Args:\n        query (str): The user\'s natural language query (e.g., "How many breweries are in Texas?")\n\n    Returns:\n        str: The answer returned from the MCP backend or an error message.\n    """\n    try:\n        # Connect to the locally running FastAPI MCP server\n        response = requests.post(\n            "http://localhost:3000/invoke",  # Updated to match your working MCP endpoint\n            json={"input": query},  # The FastAPI server expects an \'input\' key\n            timeout=10\n        )\n        response.raise_for_status()\n        data = response.json()\n        print("[MCP DEBUG] Response JSON:", data)\n        \n        # Extract the output from the MCP response\n        if "output" in data:\n            return data["output"]\n        elif "error" in data:\n            return f"Sorry, something went wrong: {data[\'error\']}"\n        else:\n            return "Sorry, I couldn\'t find an answer. Unexpected response format."\n    except Exception as e:\n        print(f"[MCP ERROR] {str(e)}")\n        return f"Sorry, I encountered an issue while fetching brewery data. Error: {str(e)}"\n', source_type='python', tags=['brewery', 'state', 'mcp'], tool_type='custom', updated_at='2025-04-10T18:28:08.212617+00:00', metadata={}), ToolSchema(args_json_schema=None, created_at='2025-04-10T18:13:52.802734+00:00', description='Get information about California breweries', json_schema=ToolJsonSchema(name='california_breweries', description='Get a complete list and count of all breweries in California.', parameters=ParametersSchema(type='object', properties={'request_heartbeat': ParameterProperties(type='boolean', description='Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.')}, required=['request_heartbeat']), type=None, required=[]), name='california_breweries', return_char_limit=6000, source_code='\nimport requests\nimport json\n\ndef california_breweries(request_heartbeat: bool = False) -> str:\n    """\n    Get a complete list and count of all breweries in California.\n\n    Args:\n        request_heartbeat: Request an immediate heartbeat after function execution\n\n    Returns:\n        JSON string containing all brewery information\n    """\n    base_url = "https://api.openbrewerydb.org/v1/breweries"\n    params = {\n        \'by_state\': \'california\',\n        \'per_page\': 200\n    }\n\n    try:\n        all_breweries = []\n        page = 1\n        while True:\n            params[\'page\'] = page\n            response = requests.get(base_url, params=params)\n            response.raise_for_status()\n            breweries = response.json()\n            if not breweries:\n                break\n            all_breweries.extend(breweries)\n            page += 1\n            if page > 20:\n                break\n\n        type_counts = {}\n        for brewery in all_breweries:\n            brewery_type = brewery.get(\'brewery_type\', \'unknown\')\n            type_counts[brewery_type] = type_counts.get(brewery_type, 0) + 1\n\n        formatted_breweries = [\n            {\n                "name": b.get("name"),\n                "city": b.get("city"),\n                "type": b.get("brewery_type"),\n                "website": b.get("website_url"),\n                "street": b.get("street"),\n                "state": b.get("state"),\n                "postal_code": b.get("postal_code"),\n                "phone": b.get("phone")\n            }\n            for b in all_breweries\n        ]\n\n        return json.dumps({\n            "total_breweries": len(all_breweries),\n            "type_breakdown": type_counts,\n            "breweries": formatted_breweries\n        }, indent=2)\n\n    except requests.exceptions.RequestException as e:\n        return json.dumps({\n            "error": f"Failed to fetch brewery data: {str(e)}"\n        })\n', source_type='python', tags=['brewery', 'california', 'search'], tool_type='custom', updated_at='2025-04-10T18:13:52.802734+00:00', metadata={})] updated_at='2025-04-10T18:28:08.292405+00:00' version='0.6.47'